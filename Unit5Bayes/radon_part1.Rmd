---
title: "Bayesian inference for radon data - part I"
author: "Leontine Alkema"
date: "April 23 2021"
output: 
  pdf_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
#library(brms)
```

# Radon

Read in the data and process (little more than we need for just estimating mean radon)
```{r}
# house level data
d <- read.table(url("http://www.stat.columbia.edu/~gelman/arm/examples/radon/srrs2.dat"), header=T, sep=",")

# deal with zeros, select what we want, make a fips (county) variable to match on 
d <- d %>% 
  mutate(activity = ifelse(activity==0, 0.1, activity)) %>% 
  mutate(fips = stfips * 1000 + cntyfips) %>%   
  dplyr::select(fips, state, county, floor, activity)

# county level data
cty <- read.table(url("http://www.stat.columbia.edu/~gelman/arm/examples/radon/cty.dat"), header = T, sep = ",")
cty <- cty %>% mutate(fips = 1000 * stfips + ctfips) %>% dplyr::select(fips, Uppm)

# filter to just be minnesota, join them and then select the variables of interest. 
dmn <- d %>% 
  filter(state=="MN") %>% 
  dplyr::select(fips, county, floor, activity) %>% 
  left_join(cty)
head(dmn)

```

Let's focus on log radon measurements
```{r}
y <- log(dmn$activity)
tibble(log_radon = y) %>%
  ggplot(aes(x = log_radon)) +
  geom_histogram() 
                                  
```

Estimate $\mu$, assume a value for $\sigma$
```{r}
# data
ybar <- mean(y)
sd.y <- sd(y)
n <- length(y)
# fix sigma
sigma <- sd.y
sd.ybar <- sigma/sqrt(n)

# prior settings 
mu0 <- ybar # prior mean 
sigma.mu0 <- sd.y # prior sd
```

Prior and posterior for $\mu$
```{r}
mupost.mean <- (mu0/(sigma.mu0^2) + n*ybar/(sigma^2))/(1/(sigma.mu0^2) + n/(sigma^2))
mupost.sd <- sqrt(1/(1/(sigma.mu0^2)+n/(sigma^2)))
mupost.mean
mupost.sd
```

## Plot prior, likelihood function, and posterior 

You may want to adjust this mugrid (x axis) when like or prior have a very large SD
```{r}
mugrid <- seq(
  min(mu0 - 3*sigma.mu0, mupost.mean - 3*mupost.sd, mupost.mean - 3*mupost.sd),
  max(mu0 + 3*sigma.mu0, mupost.mean + 3*mupost.sd, mupost.mean + 3*mupost.sd),
  length.out = 3000)
prior.dens <- dnorm(x = mugrid, mean = mu0 , sd = sigma.mu0)
post.dens <- dnorm(x = mugrid, mean = mupost.mean, sd = mupost.sd )
like.dens <- dnorm(x = mugrid, mean = ybar, sd = sd.ybar)
p <- tibble(dens = c(prior.dens, post.dens, like.dens), 
             dtype = rep(c("prior", "post", "like"), each = length(mugrid)), 
            mugrid = rep(mugrid, 3)) %>% 
    mutate(type = factor(dtype, levels = c("prior", "like", "post"))) %>%
    ggplot(aes(x = mugrid, y = dens, col = dtype, lty = dtype))   +
    geom_line(size = 1.2) +
    theme_minimal() +
    ylab("Density") +
    xlab(expression(mu)) +
    theme(legend.position = "top",
          legend.title = element_blank(),
          text = element_text(size = 15))
p
```

## Summarize the posterior

Bayesian inference 
```{r}
mupost.mean # posterior mean
qnorm(0.5, mean = mupost.mean, sd = mupost.sd) # posterior median
qnorm(c(0.025, 0.975), mean = mupost.mean, sd = mupost.sd) # 95% quantile-based CI
```

Frequentist inference

```{r}
ybar + qnorm(c(0.025, 0.975))*sd.ybar
```


# Peak at part II

Monte carlo approximation 





```{r}
fit <- brm(y ~ 1, family = gaussian(), data = tibble(y))
```

```{r}
summary(fit) 
plot(fit, pars = c("Intercept", "sigma")) 
```

Pull out the samples and create your own summaries, plot prior and post




